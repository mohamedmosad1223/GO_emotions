{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets transformers torch scikit-learn\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset,Dataset\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndataset = load_dataset(\"Keyurjotaniya007/go-emotions-cleaned\")\n\n#  train, validation, test to DataFrame\ntrain_df = pd.DataFrame(dataset['train'])\ntest_df  = pd.DataFrame(dataset['test'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\n# ÿßŸÑŸÉŸàÿØ ÿØŸá ŸáŸäŸÇŸàŸÑŸÉ ÿ•ÿ∞ÿß ŸÉÿßŸÜ PyTorch ÿ¥ÿßŸäŸÅ ÿßŸÑŸÄ GPU ŸàŸÑÿß ŸÑÿ£\nif torch.cuda.is_available():\n    print(f\"GPU is available! üî•\")\n    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\nelse:\n    print(f\"GPU is NOT available. üò≠ Make sure you have selected the GPU accelerator in the notebook settings.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install transformers accelerate -U","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T20:06:13.253375Z","iopub.execute_input":"2025-10-20T20:06:13.253877Z","iopub.status.idle":"2025-10-20T20:06:16.847997Z","shell.execute_reply.started":"2025-10-20T20:06:13.253853Z","shell.execute_reply":"2025-10-20T20:06:16.847017Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.57.1)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.11.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.19.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.35.3)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.9.18)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.1.0)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport re\nimport string\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\nfrom datasets import load_dataset, Dataset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T20:06:20.423145Z","iopub.execute_input":"2025-10-20T20:06:20.423774Z","iopub.status.idle":"2025-10-20T20:06:29.804005Z","shell.execute_reply.started":"2025-10-20T20:06:20.423745Z","shell.execute_reply":"2025-10-20T20:06:29.803195Z"}},"outputs":[{"name":"stderr","text":"2025-10-20 20:06:26.046178: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760990786.068970     302 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760990786.075854     302 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"print(\"Loading dataset...\")\ndataset = load_dataset(\"Keyurjotaniya007/go-emotions-cleaned\")\ndf = pd.DataFrame(dataset['train'])\n\ndf_sample = df.sample(frac=0.4, random_state=42)\nprint(f\"Using {len(df_sample)} rows for training and validation (40% of original data).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T20:19:01.044010Z","iopub.execute_input":"2025-10-20T20:19:01.044375Z","iopub.status.idle":"2025-10-20T20:19:07.052648Z","shell.execute_reply.started":"2025-10-20T20:19:01.044351Z","shell.execute_reply":"2025-10-20T20:19:07.051759Z"}},"outputs":[{"name":"stdout","text":"Loading dataset...\nUsing 74812 rows for training and validation (40% of original data).\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"\ndef clean_text(text):\n    text = text.lower()\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    text = re.sub(r'\\d+', '', text)\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\nprint(\"Cleaning text data...\")\ndf_sample['text'] = df_sample['text'].apply(clean_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T20:19:09.248712Z","iopub.execute_input":"2025-10-20T20:19:09.249562Z","iopub.status.idle":"2025-10-20T20:19:10.065637Z","shell.execute_reply.started":"2025-10-20T20:19:09.249535Z","shell.execute_reply":"2025-10-20T20:19:10.064791Z"}},"outputs":[{"name":"stdout","text":"Cleaning text data...\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"\nlabels = [\n    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', \n    'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', \n    'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', \n    'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', \n    'relief', 'remorse', 'sadness', 'surprise', 'neutral'\n]\nid2label = {i: label for i, label in enumerate(labels)}\nlabel2id = {label: i for i, label in enumerate(labels)}\n\ntrain_df, val_df = train_test_split(\n    df_sample,\n    test_size=0.2,\n    random_state=42,\n    stratify=df_sample['label']\n)\ntrain_dataset = Dataset.from_pandas(train_df.reset_index(drop=True))\nval_dataset = Dataset.from_pandas(val_df.reset_index(drop=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T20:19:13.010445Z","iopub.execute_input":"2025-10-20T20:19:13.011006Z","iopub.status.idle":"2025-10-20T20:19:13.116334Z","shell.execute_reply.started":"2025-10-20T20:19:13.010982Z","shell.execute_reply":"2025-10-20T20:19:13.115536Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"model_name = \"bert-base-uncased\"\nprint(f\"Loading model and tokenizer: {model_name}\")\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    num_labels=len(labels),\n    id2label=id2label,\n    label2id=label2id\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T20:19:17.315828Z","iopub.execute_input":"2025-10-20T20:19:17.316463Z","iopub.status.idle":"2025-10-20T20:19:18.308178Z","shell.execute_reply.started":"2025-10-20T20:19:17.316436Z","shell.execute_reply":"2025-10-20T20:19:18.307288Z"}},"outputs":[{"name":"stdout","text":"Loading model and tokenizer: bert-base-uncased\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"def tokenize_function(examples):\n    return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=128)\n\nprint(\"Tokenizing datasets...\")\ntrain_tokenized = train_dataset.map(tokenize_function, batched=True)\nval_tokenized = val_dataset.map(tokenize_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T20:19:26.927059Z","iopub.execute_input":"2025-10-20T20:19:26.927360Z","iopub.status.idle":"2025-10-20T20:19:35.503322Z","shell.execute_reply.started":"2025-10-20T20:19:26.927338Z","shell.execute_reply":"2025-10-20T20:19:35.502553Z"}},"outputs":[{"name":"stdout","text":"Tokenizing datasets...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/59849 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fd1a06712f2467493d9689dbfc9931b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/14963 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b4f04325ccf41698edde15ccedde704"}},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    f1 = f1_score(labels, predictions, average=\"weighted\")\n    acc = accuracy_score(labels, predictions)\n    return {\"accuracy\": acc, \"f1_weighted\": f1}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T20:19:39.205432Z","iopub.execute_input":"2025-10-20T20:19:39.205733Z","iopub.status.idle":"2025-10-20T20:19:39.210191Z","shell.execute_reply.started":"2025-10-20T20:19:39.205701Z","shell.execute_reply":"2025-10-20T20:19:39.209270Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=3,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    fp16=True,\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    logging_strategy=\"steps\",\n    logging_steps=100,\n    save_strategy=\"epoch\",\n    report_to=\"none\"\n)\n\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_tokenized,\n    eval_dataset=val_tokenized,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T20:19:42.963429Z","iopub.execute_input":"2025-10-20T20:19:42.964235Z","iopub.status.idle":"2025-10-20T20:19:43.193717Z","shell.execute_reply.started":"2025-10-20T20:19:42.964203Z","shell.execute_reply":"2025-10-20T20:19:43.192858Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_302/322557056.py:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"print(\"Starting training... üöÄ\")\ntrainer.train()\nprint(\"Training finished! ‚úÖ\")\n\n\nprint(\"\\nEvaluating the final model on the validation set...\")\neval_results = trainer.evaluate()\nprint(f\"Final Evaluation Results: {eval_results}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T20:19:46.304280Z","iopub.execute_input":"2025-10-20T20:19:46.304560Z","iopub.status.idle":"2025-10-20T20:54:11.656061Z","shell.execute_reply.started":"2025-10-20T20:19:46.304541Z","shell.execute_reply":"2025-10-20T20:54:11.655338Z"}},"outputs":[{"name":"stdout","text":"Starting training... üöÄ\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5613' max='5613' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5613/5613 33:30, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>2.880700</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>2.592800</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>2.437200</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>2.316000</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>2.242400</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>2.181900</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>2.157900</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>2.158500</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>2.140600</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>2.110600</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>2.101900</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>2.067800</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>2.022200</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>2.066700</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>2.048600</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>2.023200</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>2.017300</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>2.011500</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>1.959300</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>1.894100</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>1.864500</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>1.895500</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>1.881400</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>1.917000</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>1.898000</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>1.870900</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>1.853300</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>1.846500</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>1.919600</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>1.886800</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>1.865100</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>1.864800</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>1.836500</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>1.822100</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>1.843700</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>1.884800</td>\n    </tr>\n    <tr>\n      <td>3700</td>\n      <td>1.826700</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>1.808700</td>\n    </tr>\n    <tr>\n      <td>3900</td>\n      <td>1.729800</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>1.750100</td>\n    </tr>\n    <tr>\n      <td>4100</td>\n      <td>1.751100</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>1.722100</td>\n    </tr>\n    <tr>\n      <td>4300</td>\n      <td>1.709400</td>\n    </tr>\n    <tr>\n      <td>4400</td>\n      <td>1.750400</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>1.734200</td>\n    </tr>\n    <tr>\n      <td>4600</td>\n      <td>1.735700</td>\n    </tr>\n    <tr>\n      <td>4700</td>\n      <td>1.734800</td>\n    </tr>\n    <tr>\n      <td>4800</td>\n      <td>1.721200</td>\n    </tr>\n    <tr>\n      <td>4900</td>\n      <td>1.744600</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>1.732400</td>\n    </tr>\n    <tr>\n      <td>5100</td>\n      <td>1.694500</td>\n    </tr>\n    <tr>\n      <td>5200</td>\n      <td>1.682400</td>\n    </tr>\n    <tr>\n      <td>5300</td>\n      <td>1.759900</td>\n    </tr>\n    <tr>\n      <td>5400</td>\n      <td>1.693900</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>1.758200</td>\n    </tr>\n    <tr>\n      <td>5600</td>\n      <td>1.709000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Training finished! ‚úÖ\n\nEvaluating the final model on the validation set...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='468' max='468' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [468/468 00:53]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Final Evaluation Results: {'eval_loss': 1.99428391456604, 'eval_accuracy': 0.4119494753725857, 'eval_f1_weighted': 0.38941764902890247, 'eval_runtime': 53.7453, 'eval_samples_per_second': 278.406, 'eval_steps_per_second': 8.708, 'epoch': 3.0}\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}